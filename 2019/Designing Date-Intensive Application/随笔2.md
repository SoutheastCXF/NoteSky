1. 对于Hadoop这样的批处理系统，通常关心的是吞吐量(throughput),即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间。
2. 对于在线系统，通常更重要的是服务的响应时间(response time)，即客户端发送请求到接收响应之间的时间。

延迟（latency）和响应时间（response time）经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（服务时间（service time））之外，还包括网络延迟和排队延迟。延迟是某个请求等待处理的持续时长，在此期间它处于**休眠（latent）**状态，并等待服务。

利用数值分析每个响应的请求时间：**中位数**

响应时间的高百分位点（也称为**尾部延迟（tail latencies）**）非常重要，因为它们直接影响用户的服务体验。**例如亚马逊在描述内部服务的响应时间要求时以99.9百分位点为准，即使它只影响一千个请求中的一个**。这是因为请求响应最慢的客户往往也是数据最多的客户，也可以说是最有价值的客户 —— 因为他们掏钱了。保证网站响应迅速对于保持客户的满意度非常重要，亚马逊观察到：响应时间增加100毫秒，销售量就减少1％；而另一些报告说：慢 1 秒钟会让客户满意度指标减少16%。
